{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "from llama_index.core import Document, VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.vector_stores import VectorStoreQueryResult\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.core import Settings\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_tables_as_markdown(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    markdown_tables = []\n",
    "    for table in doc.tables:\n",
    "        rows = []\n",
    "        for row in table.rows:\n",
    "            cells = [cell.text.strip() for cell in row.cells]\n",
    "            rows.append(\"| \" + \" | \".join(cells) + \" |\")\n",
    "        if rows:\n",
    "            header = rows[0]\n",
    "            separator = \"| \" + \" | \".join([\"---\"] * len(table.columns)) + \" |\"\n",
    "            markdown_table = \"\\n\".join([header, separator] + rows[1:])\n",
    "            markdown_tables.append(markdown_table)\n",
    "    return markdown_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 .docx file(s):\n",
      "  ‚Ä¢ documents/FA-G-02_StaffReimbursement_SectionAware.docx\n",
      "  ‚Ä¢ documents/CPAX-FN-005_ProjectInvestment_SectionAware.docx\n",
      "  ‚Ä¢ documents/FA-G-15_SectionAware_Final_Sectioned.docx\n",
      "  ‚Ä¢ documents/FA-G-17_SectionAwareChunking.docx\n",
      "  ‚Ä¢ documents/FA-G-07_NonTradeSupplier_SectionAware.docx\n",
      "  ‚Ä¢ documents/FA-B2B-01_CreditMgmt_SectionAware.docx\n",
      "  ‚Ä¢ documents/FA-G-08 ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏£‡∏≤‡∏¢‡∏à‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Purchase Requisition_‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á.docx\n",
      "Loaded 7 raw Document(s) from all .docx files.\n",
      "After splitting, we have 122 chunked Documents (nodes).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.file import DocxReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# CONFIGURATION\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "# 1) Directory where all your .docx files live\n",
    "DOCX_FOLDER = \"documents/\"\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# STEP 1: Discover all .docx files\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "all_paths = glob.glob(os.path.join(DOCX_FOLDER, \"*.docx\"))\n",
    "print(f\"Found {len(all_paths)} .docx file(s):\")\n",
    "for p in all_paths:\n",
    "    print(\"  ‚Ä¢\", p)\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# STEP 2: Load each DOCX and wrap as Document\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "reader = DocxReader()\n",
    "raw_documents = []\n",
    "for file_path in all_paths:\n",
    "    # load_data returns a list of in‚Äêmemory ‚Äúpage‚Äù objects \n",
    "    docx_pages = reader.load_data(file_path)\n",
    "    for page_obj in docx_pages:\n",
    "        raw_documents.append(\n",
    "            Document(\n",
    "                text=page_obj.text,\n",
    "                metadata={\"source\": os.path.basename(file_path)}\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Loaded {len(raw_documents)} raw Document(s) from all .docx files.\")\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# STEP 3: Chunk each Document semantically\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "nodes = []\n",
    "for doc in raw_documents:\n",
    "    chunks = splitter.split_text(doc.text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        nodes.append(\n",
    "            Document(\n",
    "                text=chunk,\n",
    "                metadata={**doc.metadata, \"chunk_id\": i}\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"After splitting, we have {len(nodes)} chunked Documents (nodes).\")\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# FINAL: Assign to `documents` so the rest of your pipeline can stay unchanged\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "\n",
    "documents = nodes\n",
    "\n",
    "# Now you can call your index creation exactly as before:\n",
    "# from llama_index.core.embeddings import CohereEmbedding  # or whichever embed_model you use\n",
    "# from llama_index.core.storage import StorageContext\n",
    "# from llama_index.vector_stores import QdrantVectorStore\n",
    "# from llama_index import VectorStoreIndex\n",
    "\n",
    "# Example (adjust embed_model, storage_context, etc. to your configuration):\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents=documents,\n",
    "#     embed_model=Settings.embed_model,\n",
    "#     storage_context=storage_context,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Cohear Embedding service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Using Cohere key:    Iyn2rmOdEgiUKfxptJDhCKRwgfeIWhZ37sxzKUAc\n",
      "üî¢ Using Cohere model:  embed-multilingual-light-v3.0\n"
     ]
    }
   ],
   "source": [
    "# ‚Ä¶ (no need to call load_dotenv() here) ‚Ä¶\n",
    "\n",
    "# Hard-code your key and model ID:\n",
    "COHEAR_KEY      = \"Iyn2rmOdEgiUKfxptJDhCKRwgfeIWhZ37sxzKUAc\"\n",
    "COHEAR_MODEL_ID = \"embed-multilingual-light-v3.0\"\n",
    "\n",
    "print(\"üîë Using Cohere key:   \", COHEAR_KEY)\n",
    "print(\"üî¢ Using Cohere model: \", COHEAR_MODEL_ID)\n",
    "\n",
    "embed_model = CohereEmbedding(\n",
    "    api_key=COHEAR_KEY,\n",
    "    model_name=COHEAR_MODEL_ID,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_type=\"float\",\n",
    ")\n",
    "\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innitiates VectorStore database (Qdrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/qxv1ygl57v34c8nqkcj1m3200000gn/T/ipykernel_10595/2846219684.py:2: UserWarning: Api key is used with an insecure connection.\n",
      "  client = QdrantClient(url=\"http://localhost:6334\", api_key=os.getenv(\"QDRANT_API_KEY\"),  prefer_grpc=True)\n"
     ]
    }
   ],
   "source": [
    "# creates a persistant index to disk\n",
    "client = QdrantClient(url=\"http://localhost:6334\", api_key=os.getenv(\"QDRANT_API_KEY\"),  prefer_grpc=True)\n",
    "\n",
    "# # delete collection if it exists\n",
    "if client.collection_exists(os.getenv(\"QDANT_COLLENCTION_NAME\")):\n",
    "    client.delete_collection(os.getenv(\"QDANT_COLLENCTION_NAME\"))\n",
    "\n",
    "# create our vector store with hybrid indexing enabled\n",
    "vector_store = QdrantVectorStore(\n",
    "    os.getenv(\"QDANT_COLLENCTION_NAME\"),\n",
    "    client=client,\n",
    "    enable_hybrid=True,\n",
    "    batch_size=20,\n",
    "    prefer_grpc=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start embedding process.... into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents, embed_model=embed_model, storage_context=storage_context,\n",
    ")\n",
    "COHERE_KEY = os.getenv(\"COHEAR_API_KEY\")\n",
    "COHEAR_MODEL = os.getenv(\"COHEAR_MODEL_ID\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6334\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\", None)\n",
    "COLLECTION_NAME = os.getenv(\"QDANT_COLLENCTION_NAME\", \"my_collection\")\n",
    "\n",
    "if not COHERE_KEY:\n",
    "    raise RuntimeError(\"COHERE_API_KEY is not set in your environment\")\n",
    "\n",
    "# 2) (Re)initialize the Cohere embedder with the new API key\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=COHERE_KEY,\n",
    "    model_name=COHEAR_MODEL,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_type=\"float\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to retrive relavent nodes with question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    api_key=os.getenv(\"COHEAR_API_KEY\"),\n",
    "    model_name=os.getenv(\"COHEAR_MODEL_ID\"),\n",
    "    input_type=\"search_query\",\n",
    "    embedding_type=\"float\",\n",
    ")\n",
    "\n",
    "search_query_retriever = index.as_retriever()\n",
    "\n",
    "search_query_retrieved_nodes = search_query_retriever.retrieve(\n",
    "\"Do all Walmart locations offer scan & go?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0d70a22c-d297-4d7b-a5e1-73705e22ba8b<br>**Similarity:** 0.17325928807258606<br>**Text:** ‡∏™‡∏≤‡∏¢‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏≤‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡∏°‡∏Ç‡∏≤‡∏¢ B2B\n",
       "\n",
       "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Lotus‚Äôs : \n",
       "\n",
       "Go-fresh : ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (Area General Manager ‚Äì AGM)\n",
       "\n",
       "Hypermarket ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡πÉ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤ : ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤ (Store Manager) ->‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (Area General Manager ‚Äì AGM)\n",
       "\n",
       "Hypermarket ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤ : ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≤‡∏¢ (Zone Manager) -> ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏ß‡∏∏‡πÇ‡∏™‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≤‡∏¢ (Senior Zone Manager)\n",
       "\n",
       "‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Makro : ‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡πà‡∏≤‡∏¢‡∏Ç‡∏≤‡∏¢ (Sales Manager) ->‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡πà‡∏≤‡∏¢‡∏Ç‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ (Regional Sales Manager)\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÜ‡∏Ç‡∏≠‡∏á B2B ‡∏ó‡∏µ‡πà‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ Policy\n",
       "\n",
       "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á  Open new CV - ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà  ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° : ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏£‡∏≤‡∏¢‡∏ô‡∏µ‡πâ‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Ñ‡∏¢‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ø‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö : ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏Ç‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏ú‡∏π‡πâ‡πÄ‡∏™‡∏µ‡∏¢‡∏†‡∏≤‡∏©‡∏µ 13 ‡∏´‡∏•‡∏±‡∏Å (Tax ID) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö smartsoft\n",
       "\n",
       "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á  Open new CV - ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà  ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° : ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà?  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö : ‡∏Å‡∏£‡∏ì‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ ‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡πÉ‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤+‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏±‡∏ï‡∏£‡∏Ç‡πâ‡∏≤‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤/‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á/‡∏ú‡∏π‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£/‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£/‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏≠‡∏≥‡∏ô‡∏≤‡∏à+‡∏£‡∏π‡∏õ‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏ã‡∏•‡∏ü‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡∏õ‡πâ‡∏≤‡∏¢‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô/‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ø) ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏ö‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ‡∏Ñ‡∏∑‡∏≠‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏´‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≤‡∏°‡∏±‡∏ç‡πÅ‡∏•‡∏∞/‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡πÉ‡∏ö‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°(‡∏†‡∏û.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e1a6da9c-c96f-4e04-bf77-8dd6de24cf92<br>**Similarity:** 0.1716158092021942<br>**Text:** ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡πÅ‡∏°‡∏™ 2.‡∏≠‡∏¢‡πà‡∏≤‡πÅ‡∏ô‡∏ö‡∏£‡∏π‡∏õ‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô (Mirror) 3.‡∏™‡∏ß‡∏°‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Ç‡∏ß‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô\n",
       "\n",
       "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á  Open new CV - ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà  ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° : ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡πÑ‡∏õ‡∏û‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏à‡∏∞‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö : ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ô‡∏ö‡∏£‡∏π‡∏õ‡πÄ‡∏ã‡∏•‡∏ü‡∏µ‡πà‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏ô‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏ñ‡πà‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ï‡∏∂‡∏Å‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏°‡∏∏‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°\n",
       "‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏•‡πÇ‡∏Å‡πâ‡∏õ‡πâ‡∏≤‡∏¢/‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô/‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà 1.‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡πÅ‡∏°‡∏™ 2.‡∏≠‡∏¢‡πà‡∏≤‡πÅ‡∏ô‡∏ö‡∏£‡∏π‡∏õ‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô (Mirror) 3.‡∏™‡∏ß‡∏°‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Ç‡∏ß‡∏ô‡∏ö‡∏±‡∏ï‡∏£‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô\n",
       "\n",
       "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á  Open new CV - ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà  ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° : ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡πà‡∏≤‡∏¢‡∏Å‡∏±‡∏ö ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö ‡∏™‡∏ñ‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö : ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏Ñ‡∏£‡∏î‡∏¥‡∏ï‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ 0-3 ‡∏ß‡∏±‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏ô‡∏¥‡∏ï‡∏¥‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• 0-30 ‡∏ß‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ Type 70-80 \n",
       "\n",
       "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á  Open new CV - ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà  ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° : ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ COD ‡∏™‡∏î Instore ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£   ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö : ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏™‡∏î‡πÉ‡∏ô‡∏£‡πâ‡∏≤‡∏ô  Cash on Delivery (COD ‚Äì Instore)  ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å My Lotus‚Äôs ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥ CV ‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏ù‡πà‡∏≤‡∏¢‡∏Ç‡∏≤‡∏¢‡πÅ‡∏•‡∏∞ MDM ‡πÅ‡∏ï‡πà‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡∏ö‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô‡∏Ç‡∏≠‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£ user My Lotus‚Äôs<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "for n in search_query_retrieved_nodes:\n",
    "    display_source_node(n, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
