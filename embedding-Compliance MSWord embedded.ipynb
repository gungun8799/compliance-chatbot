{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def section_aware_split(text: str, max_chunk_len: int = 1500) -> list:\n",
    "    \"\"\"\n",
    "    Split text into semantic chunks using section headers and preserve structure for Q&A retrieval.\n",
    "    Adds [SECTION] tags for better metadata extraction and table grouping.\n",
    "    \"\"\"\n",
    "    # Match numbered headers (e.g., 1., 1.1) or Thai/English titles\n",
    "    section_pattern = re.compile(\n",
    "        r\"(?:^|\\n)([0-9]+\\.[0-9]*[^\\n]{0,80}|^ธุรกิจ[^\\n]+|^ศูนย์[^\\n]+|^ค่าสาธารณูปโภค[^\\n]*)\", re.MULTILINE)\n",
    "\n",
    "    parts = section_pattern.split(text)\n",
    "    grouped = []\n",
    "\n",
    "    for i in range(1, len(parts), 2):\n",
    "        header = parts[i].strip()\n",
    "        body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "        grouped.append(f\"[SECTION] {header}\\n{body}\")\n",
    "\n",
    "    # Combine multiple grouped sections into chunks within max_chunk_len\n",
    "    final_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for section in grouped:\n",
    "        if len(current_chunk) + len(section) > max_chunk_len:\n",
    "            if current_chunk:\n",
    "                final_chunks.append(current_chunk.strip())\n",
    "            current_chunk = section\n",
    "        else:\n",
    "            current_chunk += \"\\n\\n\" + section\n",
    "\n",
    "    if current_chunk:\n",
    "        final_chunks.append(current_chunk.strip())\n",
    "\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "from llama_index.core import Document, VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.vector_stores import VectorStoreQueryResult\n",
    "from qdrant_client import QdrantClient, AsyncQdrantClient\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "from llama_index.core import Settings\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "nest_asyncio.apply()\n",
    "load_dotenv(dotenv_path=\".env.dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_tables_as_markdown(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    markdown_tables = []\n",
    "    for table in doc.tables:\n",
    "        rows = []\n",
    "        for row in table.rows:\n",
    "            cells = [cell.text.strip() for cell in row.cells]\n",
    "            rows.append(\"| \" + \" | \".join(cells) + \" |\")\n",
    "        if rows:\n",
    "            header = rows[0]\n",
    "            separator = \"| \" + \" | \".join([\"---\"] * len(table.columns)) + \" |\"\n",
    "            markdown_table = \"\\n\".join([header, separator] + rows[1:])\n",
    "            markdown_tables.append(markdown_table)\n",
    "    return markdown_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 .docx file(s):\n",
      "  • documents/FA-G-15_ Trade Supplier Registration and Payment Policy.docx\n",
      "  • documents/อำนาจอนุมัติรายจ่ายสำหรับ Purchase Requisition_แปลงตาราง.docx\n",
      "  • documents/FA-G-02 (T) Staff Expense Reimbursement _15012025 (Chat bot).docx\n",
      "  • documents/CPAX-FN-005_Project Investment_TH_Final_Narrative_Chatbot.docx\n",
      "  • documents/ระเบียบปฏิบัติ เรื่อง อำนาจอนุมัติ Level of Authorization_แปลงตาราง (1).docx\n",
      "  • documents/FA-G-17  Tenant Selection and Debt Collection_Chatbot) (1).docx\n",
      "  • documents/FA-G-07 Non-Trade Supplier (Chat bot) (1).docx\n",
      "  • documents/FA-B2B-01 Credit Management for B2B_10032025_for sign_chatbot_Final_v1.docx\n",
      "Loaded 8 raw Document(s) from all .docx files.\n",
      "After splitting, we have 26 chunked Documents (nodes).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.file import DocxReader\n",
    "from llama_index.core.schema import Document\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# ——————————————\n",
    "# CONFIGURATION\n",
    "# ——————————————\n",
    "DOCX_FOLDER = \"documents/\"\n",
    "SHAREPOINT_BASE_URL = \"https://cpaxtra.sharepoint.com/sites/forms-library\"\n",
    "\n",
    "# ——————————————\n",
    "# SECTION TITLE HELPER\n",
    "# ——————————————\n",
    "def extract_section_title(chunk: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract section title from chunk marked as [SECTION] ... or fallback to first line.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"\\[SECTION\\] (.*?)\\n\", chunk)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    # fallback to first non-empty line\n",
    "    lines = [line.strip() for line in chunk.splitlines() if line.strip()]\n",
    "    return lines[0] if lines else \"unknown\"\n",
    "\n",
    "# ——————————————\n",
    "# STEP 1: Discover all .docx files\n",
    "# ——————————————\n",
    "all_paths = glob.glob(os.path.join(DOCX_FOLDER, \"*.docx\"))\n",
    "print(f\"Found {len(all_paths)} .docx file(s):\")\n",
    "for p in all_paths:\n",
    "    print(\"  •\", p)\n",
    "\n",
    "# ——————————————\n",
    "# STEP 2: Load each DOCX and wrap as Document\n",
    "# ——————————————\n",
    "reader = DocxReader()\n",
    "raw_documents = []\n",
    "for file_path in all_paths:\n",
    "    docx_pages = reader.load_data(file_path)\n",
    "    for page_obj in docx_pages:\n",
    "        raw_documents.append(\n",
    "            Document(\n",
    "                text=page_obj.text,\n",
    "                metadata={\"source\": os.path.basename(file_path)}\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Loaded {len(raw_documents)} raw Document(s) from all .docx files.\")\n",
    "\n",
    "# ——————————————\n",
    "# STEP 3: Chunk each Document semantically with metadata\n",
    "# ——————————————\n",
    "nodes = []\n",
    "for doc in raw_documents:\n",
    "    file_name = doc.metadata.get(\"source\", \"\")\n",
    "    attachment_link = f\"{SHAREPOINT_BASE_URL}/{file_name}\"\n",
    "    section_chunks = section_aware_split(doc.text)\n",
    "\n",
    "    for i, chunk in enumerate(section_chunks):\n",
    "        section_title = extract_section_title(chunk)\n",
    "        nodes.append(\n",
    "            Document(\n",
    "                text=chunk,\n",
    "                metadata={\n",
    "                    **doc.metadata,\n",
    "                    \"chunk_id\": i,\n",
    "                    \"section_title\": section_title,\n",
    "                    \"attachment_link\": attachment_link,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"After splitting, we have {len(nodes)} chunked Documents (nodes).\")\n",
    "\n",
    "# ——————————————\n",
    "# FINAL: Assign to `documents` so rest of pipeline stays unchanged\n",
    "# ——————————————\n",
    "documents = nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Cohear Embedding service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 Using Cohere key:    1g4IppS8Bq9OocS1c57AXaTIrzfNnGlUdq0mt4LF\n",
      "🔢 Using Cohere model:  embed-multilingual-light-v3.0\n"
     ]
    }
   ],
   "source": [
    "# … (no need to call load_dotenv() here) …\n",
    "\n",
    "# Hard-code your key and model ID:\n",
    "COHEAR_KEY      = \"1g4IppS8Bq9OocS1c57AXaTIrzfNnGlUdq0mt4LF\"\n",
    "COHEAR_MODEL_ID = \"embed-multilingual-light-v3.0\"\n",
    "\n",
    "print(\"🔑 Using Cohere key:   \", COHEAR_KEY)\n",
    "print(\"🔢 Using Cohere model: \", COHEAR_MODEL_ID)\n",
    "\n",
    "embed_model = CohereEmbedding(\n",
    "    api_key=COHEAR_KEY,\n",
    "    model_name=COHEAR_MODEL_ID,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_type=\"float\",\n",
    ")\n",
    "\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innitiates VectorStore database (Qdrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/qxv1ygl57v34c8nqkcj1m3200000gn/T/ipykernel_24187/3254164064.py:6: UserWarning: Api key is used with an insecure connection.\n",
      "  client = QdrantClient(\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "import os\n",
    "\n",
    "# Initialize Qdrant client with HTTP (not gRPC)\n",
    "client = QdrantClient(\n",
    "    url=\"http://localhost:6433\",  # Using HTTP endpoint exposed by Docker\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
    "    prefer_grpc=False,            # Disable gRPC to avoid connection issues\n",
    "    timeout=60,\n",
    "    check_compatibility=False     # Suppress version mismatch warning\n",
    ")\n",
    "\n",
    "# Load collection name from environment\n",
    "collection_name = os.getenv(\"QDRANT_COLLECTION_NAME\")\n",
    "\n",
    "# Delete collection if it exists\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "\n",
    "# Create Qdrant vector store with hybrid search enabled\n",
    "vector_store = QdrantVectorStore(\n",
    "    collection_name=collection_name,\n",
    "    client=client,\n",
    "    enable_hybrid=True,\n",
    "    batch_size=20,\n",
    "    prefer_grpc=False             # Match client setting\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start embedding process.... into vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ COHERE_API_KEY loaded.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Hardcoded API key and model config (no .env loading)\n",
    "COHERE_API_KEY = \"4mXlJe9QpUGIXxftxHgyqjw81TODwvQ2NsWq57ut\"\n",
    "COHERE_MODEL_ID = \"embed-multilingual-light-v3.0\"  # <-- replace with your actual model if different\n",
    "\n",
    "QDRANT_URL = \"http://localhost:6334\"\n",
    "QDRANT_API_KEY = None  # Set this to your Qdrant key if needed\n",
    "COLLECTION_NAME = \"my_collection\"\n",
    "\n",
    "print(\"✅ COHERE_API_KEY loaded.\")\n",
    "\n",
    "# ✅ Initialize Cohere embed model\n",
    "embed_model = CohereEmbedding(\n",
    "    cohere_api_key=COHERE_API_KEY,\n",
    "    model_name=COHERE_MODEL_ID,\n",
    "    input_type=\"search_document\",\n",
    "    embedding_type=\"float\",\n",
    ")\n",
    "\n",
    "# ✅ Build index from documents\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    embed_model=embed_model,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to retrive relavent nodes with question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "    model_name=os.getenv(\"COHERE_MODEL_ID\"),\n",
    "    input_type=\"search_query\",\n",
    "    embedding_type=\"float\",\n",
    ")\n",
    "\n",
    "search_query_retriever = index.as_retriever()\n",
    "\n",
    "search_query_retrieved_nodes = search_query_retriever.retrieve(\n",
    "\"Do all Walmart locations offer scan & go?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 62868c9f-6e21-4f0d-9d57-7ee56eb9b0d7<br>**Similarity:** 0.05706907<br>**Text:** [SECTION] 4.2\tตรวจสอบความครบถ้วนของเอกสารประกอบ หากไม่ครบถ้วนจะระบุเอกสารที่ขาดหายไป\n",
       "\n",
       "\n",
       "[SECTION] 4.3\tตรวจสอบสถานะทางการเงิน และทำ Due diligence ตามหลักเกณฑ์ (Criteria) ที่ระบุใน เอ\n",
       "กสารแนบ ข<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** f1924cb5-c00b-47aa-9cad-bb185a371a14<br>**Similarity:** 0.052682422<br>**Text:** 000,000 บาท จะต้องได้รับอนุมัติจาก Group CEO\n",
       "\n",
       "\t\n",
       "\n",
       "\tธุรกิจค้าปลีก ส่วนงาน Retail Operation ค่าใช้จ่ายทั่วไป\n",
       "\n",
       "\t- มูลค่ารายการไม่เกิน 10,000 บาท จะต้องได้รับอนุมัติจากตำแหน่ง Store Manager ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 10,001 - 30,000 บาท จะต้องได้รับอนุมัติจากตำแหน่ง Area General Manager ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 30,001 - 100,000 บาท จะต้องได้รับอนุมัติจากตำแหน่ง Director - Region Operations (RD) ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 100,001 - 3,000,000 บาท จะต้องได้รับอนุมัติจาก Director ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 3,000,001 - 20,000,000 บาท จะต้องได้รับอนุมัติจาก Senior Director ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 20,000,001 - 25,000,000 บาท จะต้องได้รับอนุมัติจาก Chief (Division) ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 25,000,001 - 28,000,000 บาท จะต้องได้รับอนุมัติจาก Chief (Function) ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 28,000,001 - 30,000,000 บาท จะต้องได้รับอนุมัติจาก Group Chief (Function) Officer ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 30,000,001 - 100,000,000 บาท จะต้องได้รับอนุมัติจาก CEO\n",
       "\n",
       "\t- มูลค่ารายการมากกว่า 100,000,000 บาท จะต้องได้รับอนุมัติจาก Group CEO\n",
       "\n",
       "\t\n",
       "\n",
       "\tธุรกิจค้าปลีก ส่วนงาน Retail Operation ค่าสาธารญูปโภค Hypermarket\n",
       "\n",
       "\t- มูลค่ารายการไม่เกิน 100,000 บาท จะต้องได้รับอนุมัติจากตำแหน่ง Store Manager ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 100,001 - 200,000 บาท จะต้องได้รับอนุมัติจากตำแหน่ง Area General Manager ขึ้นไป\n",
       "\n",
       "\t- มูลค่ารายการ 200,001 - 300,<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "for n in search_query_retrieved_nodes:\n",
    "    display_source_node(n, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
